Help on function predict in module anomalib.engine.engine:

predict(self, model: anomalib.models.components.base.anomalib_module.AnomalibModule | None = None, dataloaders: typing.Any | None = None, datamodule: anomalib.data.datamodules.base.image.AnomalibDataModule | None = None, dataset: torch.utils.data.dataset.Dataset | anomalib.data.predict.PredictDataset | None = None, return_predictions: bool | None = None, ckpt_path: str | pathlib.Path | None = None, data_path: str | pathlib.Path | None = None) -> Union[list[Any], list[list[Any]], NoneType]
    Predict using the model using the trainer.
    
    Validates the model if needed and if a validation dataloader is available. Then predicts using the model.
    
    Args:
        model (AnomalibModule | None, optional):
            Model to be used for prediction.
            Defaults to None.
        dataloaders (EVAL_DATALOADERS | None, optional):
            An iterable or collection of iterables specifying predict samples.
            Defaults to None.
        datamodule (AnomalibDataModule | None, optional):
            A :class:`~lightning.pytorch.core.datamodule.AnomalibDataModule` that defines
            the :class:`~lightning.pytorch.core.hooks.DataHooks.predict_dataloader` hook.
            The datamodule can also be a dataset that will be wrapped in a torch Dataloader.
            Defaults to None.
        dataset (Dataset | PredictDataset | None, optional):
            A :class:`~torch.utils.data.Dataset` or :class:`~anomalib.data.PredictDataset` that will be used
            to create a dataloader. Defaults to None.
        return_predictions (bool | None, optional):
            Whether to return predictions.
            ``True`` by default except when an accelerator that spawns processes is used (not supported).
            Defaults to None.
        ckpt_path (str | None, optional):
            Either ``"best"``, ``"last"``, ``"hpc"`` or path to the checkpoint you wish to predict.
            If ``None`` and the model instance was passed, use the current weights.
            Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded
            if a checkpoint callback is configured.
            Defaults to None.
        data_path (str | Path | None):
            Path to the image or folder containing images to generate predictions for.
            Defaults to None.
    
    Returns:
        _PREDICT_OUTPUT | None: Predictions.
    
    CLI Usage:
        1. you can pick a model.
            ```python
            anomalib predict --model anomalib.models.Padim
            anomalib predict --model Padim                                  --data datasets/MVTecAD/bottle/test/broken_large
            ```
        2. Of course, you can override the various values with commands.
            ```python
            anomalib predict --model anomalib.models.Padim                                  --data <CONFIG | CLASS_PATH_OR_NAME>
            ```
        4. If you have a ready configuration file, run it like this.
            ```python
            anomalib predict --config <config_file_path> --return_predictions
            ```
        5. You can also point to a folder with image or a single image instead of passing a dataset.
            ```python
            anomalib predict --model Padim --data <PATH_TO_IMAGE_OR_FOLDER> --ckpt_path <PATH_TO_CHECKPOINT>
            ```

Help on function export in module anomalib.engine.engine:

export(self, model: anomalib.models.components.base.anomalib_module.AnomalibModule, export_type: anomalib.deploy.export.ExportType | str, export_root: str | pathlib.Path | None = None, model_file_name: str = 'model', input_size: tuple[int, int] | None = None, compression_type: anomalib.deploy.export.CompressionType | None = None, datamodule: anomalib.data.datamodules.base.image.AnomalibDataModule | None = None, metric: torchmetrics.metric.Metric | str | None = None, ov_args: dict[str, typing.Any] | None = None, ov_kwargs: dict[str, typing.Any] | None = None, onnx_kwargs: dict[str, typing.Any] | None = None, ckpt_path: str | pathlib.Path | None = None) -> pathlib.Path | None
    Export the model in PyTorch, ONNX or OpenVINO format.
    
    Args:
        model (AnomalibModule): Trained model.
        export_type (ExportType): Export type.
        export_root (str | Path | None, optional): Path to the output directory. If it is not set, the model is
            exported to trainer.default_root_dir. Defaults to None.
        model_file_name (str = "model"): Name of the exported model file. If it is not set, the model is
            is called "model". Defaults to "model".
        input_size (tuple[int, int] | None, optional): A statis input shape for the model, which is exported to ONNX
            and OpenVINO format.
            Defaults to ``None.
        compression_type (CompressionType | None, optional): Compression type for OpenVINO exporting only.
            Defaults to ``None``.
        datamodule (AnomalibDataModule | None, optional): Lightning datamodule.
            Must be provided if ``CompressionType.INT8_PTQ`` or `CompressionType.INT8_ACQ`` is selected
            (OpenVINO export only).
            Defaults to ``None``.
        metric (Metric | str | None, optional): Metric to measure quality loss when quantizing.
            Must be provided if ``CompressionType.INT8_ACQ`` is selected and must return higher value for better
            performance of the model (OpenVINO export only).
            Defaults to ``None``.
        ov_args (dict[str, Any] | None, optional): Deprecated. Use ov_kwargs instead.
            This is optional and used only for OpenVINO's model optimizer.
            Defaults to None.
        ov_kwargs (dict[str, Any] | None, optional): This is optional and used only for OpenVINO's model optimizer.
            Defaults to None.
        onnx_kwargs (dict[str, Any] | None, optional): This is optional and used only for ONNX export options.
            Passed to model.to_onnx or model.to_openvino.
            See https://pytorch.org/docs/stable/onnx.html#torch.onnx.export for details.
            Defaults to ``None``.
        ckpt_path (str | Path | None): Checkpoint path. If provided, the model will be loaded from this path.
    
    Returns:
        Path: Path to the exported model.
    
    Raises:
        ValueError: If Dataset, Datamodule are not provided.
    
    CLI Usage:
        1. To export as a torch ``.pt`` file you can run the following command.
            ```python
            anomalib export --model Padim --export_type torch --ckpt_path <PATH_TO_CHECKPOINT>
            ```
        2. To export as an ONNX ``.onnx`` file you can run the following command.
            ```python
            anomalib export --model Padim --export_type onnx --ckpt_path <PATH_TO_CHECKPOINT> \
            --input_size "[256,256]"
            ```
        3. To export as an OpenVINO ``.xml`` and ``.bin`` file you can run the following command.
            ```python
            anomalib export --model Padim --export_type openvino --ckpt_path <PATH_TO_CHECKPOINT> \
            --input_size "[256,256] --compression_type FP16
            ```
        4. You can also quantize OpenVINO model with the following.
            ```python
            anomalib export --model Padim --export_type openvino --ckpt_path <PATH_TO_CHECKPOINT> \
            --input_size "[256,256]" --compression_type INT8_PTQ --data MVTec
            ```

